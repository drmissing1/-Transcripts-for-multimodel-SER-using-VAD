import os
import random
import numpy as np
import pandas as pd
import torch
import torchaudio
from transformers import AutoFeatureExtractor, AutoModelForAudioClassification

# ========== ğŸ§  è®¾ç½®å®Œå…¨ç¡®å®šæ€§ ==========
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
torch.use_deterministic_algorithms(True)

# ========== ğŸ“ è·¯å¾„è®¾ç½® ==========
wav_dir = r"D:\Multimodel SER system\project2_database\enterface wave"
csv_path = r"D:\Multimodel SER system\project2_database\outputs\transcriptions_with_VAD.csv"

# ========== ğŸ¤– æ¨¡å‹åŠ è½½ ==========
model_name = "audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim"
extractor = AutoFeatureExtractor.from_pretrained(model_name)
model = AutoModelForAudioClassification.from_pretrained(model_name)
model.eval()
device = torch.device("cpu")  # å¦‚æœæƒ³ç”¨GPUï¼Œå¯æ”¹ä¸º "cuda"
model.to(device)

# ========== ğŸ§¾ CSVè¯»å– ==========
df = pd.read_csv(csv_path)
valences, arousals, dominances = [], [], []

# ========== ğŸ” éŸ³é¢‘éå† ==========
for i, row in df.iterrows():
    wav_path = os.path.join(wav_dir, row["REC.WAV"])
    if not os.path.exists(wav_path):
        print(f"âš ï¸ æ–‡ä»¶æœªæ‰¾åˆ°ï¼š{wav_path}")
        valences.append(0.0)
        arousals.append(0.0)
        dominances.append(0.0)
        continue

    waveform, sr = torchaudio.load(wav_path)
    waveform = waveform.clone().detach()  # é˜²æ­¢éç¡®å®šæ€§ä¿®æ”¹

    # å•å£°é“åŒ–
    if waveform.shape[0] > 1:
        waveform = waveform.mean(dim=0, keepdim=True)

    # é‡é‡‡æ ·
    if sr != 16000:
        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)
        waveform = resampler(waveform)

    # è½¬ä¸º torch tensorï¼ˆä¸å†ç”¨ numpyï¼‰
    input_tensor = waveform.squeeze(0).to(device)
    inputs = extractor(input_tensor, sampling_rate=16000, return_tensors="pt")
    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        logits = model(**inputs).logits.squeeze()

    valences.append(float(logits[0]))
    arousals.append(float(logits[1]))
    dominances.append(float(logits[2]))

# ========== ğŸ’¾ å†™å…¥æ–°CSV ==========
df["AUDIO VALENCE"] = valences
df["AUDIO AROUSAL"] = arousals
df["AUDIO DOMINANCE"] = dominances

output_csv = csv_path.replace(".csv", "_with_AUDIO_VAD_deterministic1.csv")
df.to_csv(output_csv, index=False, encoding="utf-8-sig")

print(f"\nâœ… éŸ³é¢‘æƒ…ç»ªåˆ†æå®Œæˆï¼Œå…±å¤„ç† {len(df)} æ¡éŸ³é¢‘ã€‚\nä¿å­˜ç»“æœè‡³ï¼š{output_csv}")
